{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing MPII human joints\n",
    "\n",
    "This jupyter notebook contains code to visualize joints ground truth overlayed on MPII human pose images. <br>\n",
    "Since MPII annotations exist only for sufficiently separated humans, not all humans in the images have annotations. <br>\n",
    "The code snippet can also be used to understand how the MPII matlab structure file is read in Python. <br>\n",
    "\n",
    "Packages required: ```numpy, matplotlib, scipy, adjustText, tqdm```\n",
    "\n",
    "Pre-requisites: <br>\n",
    "Download MPII images from ```http://human-pose.mpi-inf.mpg.de/#download``` and paste all images ```*.jpg``` in the ```data/mpii/images``` folder. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import copy\n",
    "from pathlib import Path\n",
    "\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from adjustText import adjust_text\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.patches import Circle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the text file containing all the image names in the MPII dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path(os.getcwd()).parent\n",
    "sys.path.append(root)\n",
    "\n",
    "dataset_name = ['mpii']\n",
    "dataset_path = list(map(lambda x: os.path.join(root, 'data', x), dataset_name))\n",
    "\n",
    "# Format of filenames = [[mpii_img_1, mpii_img_2, ... (mpii_img_k)]]\n",
    "filenames_ = list(map(lambda path, name: open(os.path.join(path, '{}_filenames.txt'.format(name))), dataset_path, dataset_name))\n",
    "filenames = list(map(lambda f: f.read().split(), filenames_))\n",
    "_ = list(map(lambda f: f.close(), filenames_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Declaring the function for visualizing image and joints\n",
    "\n",
    "We color code the joints corresponding to the {right, left} + {leg, arm} and the face. <br>\n",
    "A directory is created to dump the images: ```./results/viz_gt/*.jpg``` <br>\n",
    "We then iterate over all: ```{image [i], persons [k] in image [i], joint [j] for person [k]}```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_image(image_info):\n",
    "    '''\n",
    "    :param image_info: (dict)\n",
    "    '''\n",
    "    colour = {'rankl': (0, 0, 1), 'rknee': (0, 0, 1), 'rhip': (0, 0, 1),\n",
    "              'lankl': (1, 0, 0), 'lknee': (1, 0, 0), 'lhip': (1, 0, 0),\n",
    "              'rwri': (1, 1, 0), 'relb': (1, 1, 0), 'rsho': (1, 1, 0),\n",
    "              'lwri': (0, 1, 0), 'lelb': (0, 1, 0), 'lsho': (0, 1, 0),\n",
    "              'head': (0, 1, 1), 'thorax': (0, 1, 1), 'upper_neck': (0, 1, 1)}\n",
    "\n",
    "    os.makedirs(os.path.join(root, 'results', 'viz_gt'), exist_ok=True)\n",
    "    img_dump = os.path.join(root, 'results', 'viz_gt')\n",
    "\n",
    "    # Since we're considering only MPII, the outer loop will execute only once.\n",
    "    for dataset_name_ in image_info.keys():\n",
    "        # Iterate over all images\n",
    "        for i in tqdm(range(len(image_info[dataset_name_]['img']))):\n",
    "\n",
    "            fig, ax = plt.subplots(nrows=1, ncols=1, frameon=False)\n",
    "            ax.set_axis_off()\n",
    "\n",
    "            # Load image, gt for the given index\n",
    "            img = image_info[dataset_name_]['img'][i]\n",
    "            img_name = image_info[dataset_name_]['img_name'][i]\n",
    "            img_gt = image_info[dataset_name_]['img_gt'][i]\n",
    "\n",
    "            # Store joint names which will be displayed on the image\n",
    "            text_overlay = []\n",
    "            ax.imshow(img)\n",
    "\n",
    "            # Color-code the joint and joint name onto the image\n",
    "            joint_names = list(colour.keys())\n",
    "            for jnt in joint_names:\n",
    "                for jnt_gt in img_gt[jnt]:\n",
    "                    if jnt_gt[2]:\n",
    "                        text_overlay.append(ax.text(x=jnt_gt[0], y=jnt_gt[1], s=jnt, color=colour[jnt], fontsize=6))\n",
    "                        ax.add_patch(Circle(jnt_gt[:2], radius=1.5, color=colour[jnt], fill=False))\n",
    "\n",
    "            # Ensure no crowding of joints on the image\n",
    "            adjust_text(text_overlay)\n",
    "\n",
    "            plt.savefig(fname=os.path.join(img_dump, '{}'.format(img_name)),\n",
    "                        facecolor='black', edgecolor='black', bbox_inches='tight', dpi=300)\n",
    "\n",
    "            plt.close()\n",
    "            del fig, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing the images and ground truth \n",
    "\n",
    "The index to joint name conversion is provided on MPII website. <br>\n",
    "We load ```batch = 200``` images at a time to prevent exhausting available RAM. <br>\n",
    "The subsequent ```for``` loop(s) are used to unravel the matlab structure file to obtain the joint ground truths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [00:12<00:00, 16.41it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 122/122 [04:19<00:00,  2.13s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:07<00:00, 13.44it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 54/54 [02:33<00:00,  2.85s/it]\n"
     ]
    }
   ],
   "source": [
    "# index to joint name conversion\n",
    "mpii_idx_to_jnt = {0: 'rankl', 1: 'rknee', 2: 'rhip', 5: 'lankl', 4: 'lknee', 3: 'lhip',\n",
    "                   6: 'pelvis', 7: 'thorax', 8: 'upper_neck', 11: 'relb', 10: 'rwri', 9: 'head',\n",
    "                   12: 'rsho', 13: 'lsho', 14: 'lelb', 15: 'lwri'}\n",
    "\n",
    "# This template will then be updated as and when we read ground truth\n",
    "mpii_template = dict([(mpii_idx_to_jnt[i], []) for i in range(16)])\n",
    "\n",
    "# Load the mat file.\n",
    "matlab_mpii = scipy.io.loadmat(os.path.join(dataset_path[0], 'joints.mat'), struct_as_record=False)['RELEASE'][0, 0]\n",
    "num_images = annotation_mpii = matlab_mpii.__dict__['annolist'][0].shape[0]\n",
    "\n",
    "# Load images and GT in batches of 200\n",
    "initial_index = 0\n",
    "batch = 200\n",
    "while initial_index < num_images:\n",
    "    # Initialize empty placeholder\n",
    "    img_dict = {'mpii': {'img': [], 'img_name': [], 'img_pred': [], 'img_gt': []}}\n",
    "    \n",
    "    # Iterate over each image\n",
    "    for img_idx in tqdm(range(initial_index, min(initial_index + batch, num_images))):\n",
    "        annotation_mpii = matlab_mpii.__dict__['annolist'][0, img_idx]\n",
    "        train_test_mpii = matlab_mpii.__dict__['img_train'][0, img_idx].flatten()[0]\n",
    "        person_id = matlab_mpii.__dict__['single_person'][img_idx][0].flatten()\n",
    "\n",
    "        # Load the individual image. Throw an exception if image corresponding to filename not available.\n",
    "        img_name = annotation_mpii.__dict__['image'][0, 0].__dict__['name'][0]\n",
    "        try:\n",
    "            image = plt.imread(os.path.join(dataset_path[0], 'images', img_name))\n",
    "        except FileNotFoundError:\n",
    "            print('Could not load filename: {}'.format(img_name))\n",
    "            continue\n",
    "\n",
    "        # Avoid modifying the template and create a copy\n",
    "        gt_per_image = copy.deepcopy(mpii_template)\n",
    "\n",
    "        # Flag is set to true if atleast one person exists in the image with joint annotations.\n",
    "        # If Flag == True, then the image and GT is considered for visualization, else skip\n",
    "        annotated_person_flag = False\n",
    "        \n",
    "        # Iterate over persons\n",
    "        for person in (person_id - 1):\n",
    "            try:\n",
    "                annopoints_img_mpii = annotation_mpii.__dict__['annorect'][0, person].__dict__['annopoints'][0, 0]\n",
    "                num_joints = annopoints_img_mpii.__dict__['point'][0].shape[0]\n",
    "\n",
    "                # Iterate over present joints\n",
    "                for i in range(num_joints):\n",
    "                    x = annopoints_img_mpii.__dict__['point'][0, i].__dict__['x'].flatten()[0]\n",
    "                    y = annopoints_img_mpii.__dict__['point'][0, i].__dict__['y'].flatten()[0]\n",
    "                    id_ = annopoints_img_mpii.__dict__['point'][0, i].__dict__['id'][0][0]\n",
    "                    vis = annopoints_img_mpii.__dict__['point'][0, i].__dict__['is_visible'].flatten()\n",
    "\n",
    "                    # No entry corresponding to visible\n",
    "                    if vis.size == 0:\n",
    "                        vis = 1\n",
    "                    else:\n",
    "                        vis = vis.item()\n",
    "\n",
    "                    gt_per_joint = np.array([x, y, vis]).astype(np.float16)\n",
    "                    gt_per_image[mpii_idx_to_jnt[id_]].append(gt_per_joint)\n",
    "\n",
    "                annotated_person_flag = True\n",
    "            except KeyError:\n",
    "                # Person 'x' could not have annotated joints, hence move to person 'y'\n",
    "                continue\n",
    "\n",
    "        if not annotated_person_flag:\n",
    "            continue\n",
    "\n",
    "        # Update the template copy with image, name and ground truth\n",
    "        img_dict['mpii']['img'].append(image)\n",
    "        img_dict['mpii']['img_name'].append(img_name)\n",
    "        img_dict['mpii']['img_gt'].append(gt_per_image)\n",
    "    \n",
    "    visualize_image(img_dict)\n",
    "    initial_index += batch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
